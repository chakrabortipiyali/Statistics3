{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QNVbPrHtdXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. What is hypothesis testing in statistics?\n",
        "- Hypothesis testing is a claim or statement or an assumption about a population parameter that can be tested using statistical methods.\n",
        "In the process of Hypothesis testing , first a claim about the population is to be made regarding the parameter of the population to be calculated. Then bacause of the resource contraints whole population can not be reached to get the real picture, so a sample of the population is to be collected to measure the average value of the parameter.After that it is to be checked whether the claim is closely matching with the average of the sample or not.These total process is called Hypothesis testing."
      ],
      "metadata": {
        "id": "Pr8JgWwTxlP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "- The initial or default assumption made in Hypothesis testing is known as null hypothesis.\n",
        "- Alternative hypothesis is just the opposite of null hypothesis.\n",
        "- For example , for finding the average weight of population of India by Hypothesis testing , first a claim regarding the weight of the population is to be made . Suppose it is 55 Kg. This is called null hypothesis. Alternative hypothesis is if it is assumed that the average weight of the  population is not equal to 55 Kg."
      ],
      "metadata": {
        "id": "wC0-vibjy5Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.What is the significance level in hypothesis testing, and why is it important?\n",
        "- Significance level in hypothesis testing is the margin of error.that means if Average value of the parameter which need to be calculated does to closely match with the claimed value , there must be some margin of error.\n",
        "- Significance level is important for rejection of the values which are very far from the mean value."
      ],
      "metadata": {
        "id": "kI4S0goIFUaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. What does a P-value represent in hypothesis testing?\n",
        "- The P- value is the probability value calculated from a statistical test which is used to decide  whether to  reject a null hypothesis or not."
      ],
      "metadata": {
        "id": "tJrbFK4WUwK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. How do you interpret the P-value in hypothesis testing?\n",
        "- We know that Zscore is used to know hoe far the mean value of the sample is lying from the null hypothesis value. Using the Zscore value probability is found from the Z state table. And this probability is nothing but the P-value."
      ],
      "metadata": {
        "id": "sSRMUclaVTPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "- In hypothesis testing if null hypothesis is rejected when this is supposed to be  true is called Type I error.But when null hypothesis is reatined that means failed to reject while it is  actually false, is Type II error.\n",
        "- Example : While doing Hypothesis testing for finding out the average age of Indian population , suppose mean age is claimed as 35 i,e  Null hypothesis is 35. If after the testing this null hypothesis is rejected but actually 35 is the mean age of Indian population , then Type I error has been made. If 35 is retained as null hypothesis but actually the mean age of Indian population is something else , then Type II error has been made."
      ],
      "metadata": {
        "id": "MF5Kve881fVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "- If rejection area lies in only one side of the normal distribution curve , then this is called as one- tailed testing. In this case Alternate hypothesis will not have \"not equal to\" sign.Alternate hypothesis will be greater than or less than the null hypothesis.\n",
        "- If rejection area lies in both the sides of normal distribution curve , then this is called two-tailed test. In this case Alternate hypothesis there will be \"not equal to\" sign."
      ],
      "metadata": {
        "id": "Yu56xxL8M50Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.What is the Z-test, and when is it used in hypothesis testing?\n",
        "- Z-test is the test used for hypothesis testing in statistics.\n",
        "- Z-test is used when\n",
        "    * hypothesis test is to be done on sample collected from a very large\n",
        "      population , size of which is more than 30 and  \n",
        "    * Standard deviation of the population is provided."
      ],
      "metadata": {
        "id": "Rqsjh-GrOl_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "- The difference betwwen the mean value of the sample and the null hypothesis value with respect to standard deviation of the population is given as Zscore.\n",
        "- Zscore represents how far the is any data point which is calculated from the sample collected from a large population for hypothesis testing , from the mean value."
      ],
      "metadata": {
        "id": "OYMbIGD7P8Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "- The t-distribution is a probability distribution similar to the normal distribution, but with heavier tails. The t-distribution is characterized by its \"degrees of freedom,\" which are related to the sample size.Degree of freedom is one less than the sample size.\n",
        "- It is  used when the population standard deviation is unknown and the sample size is small, or when the population is not normally distributed."
      ],
      "metadata": {
        "id": "UPKz6DsUbpc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.What is the difference between a Z-test and a T-test?\n",
        "- While doing Hypothesis testing on a very large population if sample size is greater than 30 and standard deviation of the population is given , then Z test is used whereas T test is used if standard deviation of the population is not provided and sample size is less tha 30."
      ],
      "metadata": {
        "id": "Gd4S5mGYnvau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12.What is the T-test, and how is it used in hypothesis testing?\n",
        "- Z-test is the test used for hypothesis testing in statistics.\n",
        "- Z-test is used when\n",
        "    * hypothesis test is to be done on sample collected from a very large\n",
        "      population , size of which is less than 30 or\n",
        "    * Standard deviation of the population is not provided."
      ],
      "metadata": {
        "id": "XM3T8VuS2-Yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "- Z-tests and t-tests are both used in hypothesis testing to compare means, but they differ primarily in their assumptions about sample size and population standard deviation: Z-tests are used for large samples (n > 30) and known population standard deviation, while t-tests are for smaller samples (n < 30) or unknown population standard deviation."
      ],
      "metadata": {
        "id": "LmRCEzbA3hbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14.What is a confidence interval, and how is it used to interpret statistical results?\n",
        "- A confidence interval (CI) is a range of values used to estimate an unknown population parameter based on sample data, with a certain level of confidence  that the true value lies within that range.\n",
        "- It's used to quantify uncertainty and interpret statistical results by providing a range for the true value."
      ],
      "metadata": {
        "id": "P4x7LEFSCLKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15.What is the margin of error, and how does it affect the confidence interval?\n",
        "- The margin of error represents the potential range of uncertainty around a sample statistic, while the confidence interval is the range within which the true population parameter is likely to fall, with a specified level of confidence. The margin of error is half the width of the confidence interval"
      ],
      "metadata": {
        "id": "lZJ3dpmi9xbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16.How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "- Bayes' Theorem is a mathematical formula that describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
        "It's often used to calculate conditional probability, which is the probability of an event (A) occurring given that another event (B) has already occurred.\n",
        "The formula is: P(A|B) = [P(B|A) * P(A)] / P(B)\n",
        "P(A|B): The probability of event A occurring given that event B has occurred (posterior probability).\n",
        "P(B|A): The probability of event B occurring given that event A has occurred (likelihood).\n",
        "P(A): The prior probability of event A occurring (before considering event B).\n",
        "P(B): The probability of event B occurring (evidence).\n",
        "- Its significance lies in its ability to incorporate prior knowledge with new data to make more accurate predictions and inferences."
      ],
      "metadata": {
        "id": "yI2DkEPBAR5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17.What is the Chi-square distribution, and when is it used?\n",
        "- The Chi-square distribution is a probability distribution that describes the distribution of the sum of squares of k random variables where k is the degree of freedom.\n",
        "\n",
        "-The chi-square distribution is a continuous probability distribution used in statistical hypothesis testing, particularly for comparing observed data with expected data, and determining if there's a relationship between categorical variables."
      ],
      "metadata": {
        "id": "JNyYh0tOscWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "- The Chi-square goodness-of-fit test is a statistical method used to determine if a sample data distribution fits a hypothesized distribution or not, by comparing observed frequencies with expected frequencies. It's a non-parametric test that assesses how well a theoretical distribution (e.g., normal, binomial) fits the observed data.\n",
        "- The steps to apply this test are discussed below :\n",
        "Hypothesis: We need to start with a null hypothesis (H0) that the observed data follows the hypothesized distribution.\n",
        "Expected Frequencies: We then calculate the expected frequencies for each category based on the hypothesized distribution.\n",
        "Chi-Square Statistic: We need to compute the chi-square statistic, which measures the discrepancy between observed and expected frequencies.\n",
        "Chi critical value: We thenfind the Chi critical value, which represents the probability of observing a chi-square statistic  \n",
        "Decision: We then  compare the Chi critical value with Chi Statistics value to a significance level (alpha, usually 0.05). If theChi critical value is less than or equal to alpha, the null hypothesis is rejected, suggesting the observed data does not fit the hypothesized distribution."
      ],
      "metadata": {
        "id": "9vSGcTEk249k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "- The F-distribution is a continuous probability distribution used in hypothesis testing, particularly for comparing variances or means of two or more populations, and is commonly used in ANOVA (Analysis of Variance) and F-tests."
      ],
      "metadata": {
        "id": "XpX4qJz18uqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20.What is an ANOVA test, and what are its assumptions?\n",
        "- ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups, analyzing the variance within and between groups to determine if there are statistically significant differences. Its key assumptions include normality, homogeneity of variance, and independence of observations.\n"
      ],
      "metadata": {
        "id": "AV8srAxS9Fi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. What are the different types of ANOVA tests?\n",
        "- Different types of ANOVA tests are :\n",
        "- One way ANOVA - One factor with at least two levels which are independent.\n",
        "- Repeated measures ANOVA - One factor with at least two levels but levels are dependent.\n",
        "- Factorial ANOVA - Two or more factors each of which has at least two levels. Levels can be dependent , independent or both."
      ],
      "metadata": {
        "id": "0UwGONnD9TU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22.What is the F-test, and how does it relate to hypothesis testing?\n",
        "- The F-test is a statistical test that compares variances, used in hypothesis testing to determine if the variances of two populations or samples are significantly different, often used in ANOVA and regression analysis."
      ],
      "metadata": {
        "id": "-n7T15Mk694s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XBR-5EoGpw0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "# interpret the results\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 115  # Sample mean\n",
        "population_mean = 100  # Population mean\n",
        "sample_std = 15  # Sample standard deviation\n",
        "sample_size = 30  # Sample size\n",
        "\n",
        "# Perform Z-test\n",
        "z_score = (sample_mean - population_mean) / (sample_std / np.sqrt(sample_size))\n",
        "z_critical = stats.norm.cdf(z_score)\n",
        "alpha  = 0.05  # Significance level\n",
        "\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"z_critical: {z_critical}\")\n",
        "\n",
        "if z_critical < alpha:\n",
        "    print(\"Reject null hypothesis: Sample mean is significantly greater than population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: Sample mean is not significantly greater than population mean.\")\n"
      ],
      "metadata": {
        "id": "D-zOovRa73TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Simulate random data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=100)  # Mean=50, Std=10, n=100\n",
        "sample2 = np.random.normal(loc=52, scale=10, size=100)  # Mean=52, Std=10, n=100\n",
        "\n",
        "# Step 2: Perform a two-sample t-test\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The means are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in means.\")\n"
      ],
      "metadata": {
        "id": "QKxCu1kYr6fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def one_sample_z_test(sample, population_mean, population_std):\n",
        "\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Compute the Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Compute the p-value (two-tailed test)\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    return z_score, p_value\n",
        "\n",
        "\n",
        "sample_data = [51, 52, 53, 49, 50, 47, 52, 48, 51, 49]  #  sample\n",
        "pop_mean = 50  # Population mean\n",
        "pop_std = 2    # Population standard deviation\n",
        "\n",
        "z, p = one_sample_z_test(sample_data, pop_mean, pop_std)\n",
        "print(f\"Z-score: {z}, P-value: {p}\")\n",
        "\n",
        "# Decision Rule: If p < 0.05, reject the null hypothesis.\n",
        "if p < 0.05:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference.\")\n"
      ],
      "metadata": {
        "id": "scxmgSfXtviw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "n = 30  # Sample size\n",
        "alpha = 0.05  # Significance level\n",
        "\n",
        "# Compute the Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "\n",
        "# Critical Z-values for two-tailed test\n",
        "z_critical = stats.norm.ppf(1 - alpha/2)\n",
        "\n",
        "# Decision rule\n",
        "reject_region = (-z_critical, z_critical)\n",
        "\n",
        "# Visualization\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = stats.norm.pdf(x, 0, 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "plt.axvline(-z_critical, color='r', linestyle='dashed', label=f'Critical Value -{z_critical:.2f}')\n",
        "plt.axvline(z_critical, color='r', linestyle='dashed', label=f'Critical Value {z_critical:.2f}')\n",
        "plt.axvline(z_score, color='b', linestyle='solid', label=f'Z-score {z_score:.2f}')\n",
        "\n",
        "# Shading rejection regions\n",
        "plt.fill_between(x, y, 0, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.3)\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Two-Tailed Z-Test Decision Region\")\n",
        "plt.xlabel(\"Z-score\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.show()\n",
        "\n",
        "# Conclusion\n",
        "if z_score < -z_critical or z_score > z_critical:\n",
        "    print(f\"Reject the null hypothesis (Z={z_score:.2f})\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis (Z={z_score:.2f})\")\n"
      ],
      "metadata": {
        "id": "01NP3bL7vzL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def hypothesis_testing(mu_null=0, mu_alt=1, sigma=1, alpha=0.05, n=30):\n",
        "\n",
        "    # Compute standard error\n",
        "    se = sigma / np.sqrt(n)\n",
        "\n",
        "    # Compute critical value for rejection region\n",
        "    critical_value = norm.ppf(1 - alpha, loc=mu_null, scale=se)\n",
        "\n",
        "    # Generate x values\n",
        "    x = np.linspace(mu_null - 4*se, mu_alt + 4*se, 1000)\n",
        "\n",
        "    # Compute probability densities\n",
        "    pdf_null = norm.pdf(x, loc=mu_null, scale=se)\n",
        "    pdf_alt = norm.pdf(x, loc=mu_alt, scale=se)\n",
        "\n",
        "    # Plot distributions\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf_null, label='Null Hypothesis (H0)', color='blue')\n",
        "    plt.plot(x, pdf_alt, label='Alternative Hypothesis (H1)', color='red')\n",
        "\n",
        "    # Shade Type 1 error region (Alpha)\n",
        "    plt.fill_between(x, pdf_null, where=(x >= critical_value), color='blue', alpha=0.3, label='Type 1 Error (α)')\n",
        "\n",
        "    # Compute beta (Type 2 error probability)\n",
        "    beta = norm.cdf(critical_value, loc=mu_alt, scale=se)\n",
        "\n",
        "    # Shade Type 2 error region (Beta)\n",
        "    plt.fill_between(x, pdf_alt, where=(x < critical_value), color='red', alpha=0.3, label='Type 2 Error (β)')\n",
        "\n",
        "    # Labels and legend\n",
        "    plt.axvline(critical_value, color='black', linestyle='--', label=f'Critical Value = {critical_value:.2f}')\n",
        "    plt.title('Type 1 and Type 2 Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Test Statistic')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Critical Value: {critical_value:.2f}')\n",
        "    print(f'Type 2 Error Probability (Beta): {beta:.3f}')\n",
        "    print(f'Power of the Test (1 - Beta): {1 - beta:.3f}')\n",
        "\n",
        "# Example usage\n",
        "hypothesis_testing()"
      ],
      "metadata": {
        "id": "Az2gmUdkwl8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a Python program to perform an independent T-test and interpret the results\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Generate some sample data\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=12, size=30)\n",
        "\n",
        "# Perform independent T-test\n",
        "t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: There is a significant difference between the groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no significant difference between the groups.\")\n"
      ],
      "metadata": {
        "id": "2PUPHSaf9O3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Perform a paired sample T-test using Python and visualize the comparison results"
      ],
      "metadata": {
        "id": "FbAC42on92Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.  Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "sample_size = 30\n",
        "mu1, sigma1 = 50, 10  # Mean and standard deviation for sample 1\n",
        "mu2, sigma2 = 55, 10  # Mean and standard deviation for sample 2\n",
        "\n",
        "sample1 = np.random.normal(mu1, sigma1, sample_size)\n",
        "sample2 = np.random.normal(mu2, sigma2, sample_size)\n",
        "\n",
        "# Z-test\n",
        "pop_sigma = 10  # Assumed known population standard deviation\n",
        "z_statistic = (np.mean(sample1) - np.mean(sample2)) / (pop_sigma * np.sqrt(2/sample_size))\n",
        "z_critical_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))  # Two-tailed test\n",
        "\n",
        "# T-test (assuming unknown population standard deviation)\n",
        "t_statistic, t_critical_value = stats.ttest_ind(sample1, sample2)\n",
        "\n",
        "# Compare results\n",
        "print(f\"Z-test: Statistic = {z_statistic}, p-value = {z_critical_value}\")\n",
        "print(f\"T-test: Statistic = {t_statistic}, p-value = {t_critical_value}\")\n"
      ],
      "metadata": {
        "id": "HmHOYuVS-Zbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "import scipy.stats as st\n",
        "import numpy as np\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "\n",
        "    n = len(data)  # Sample size\n",
        "    mean = np.mean(data)  # Sample mean\n",
        "    std_err = st.sem(data)  # Standard error of the mean\n",
        "    margin_of_error = std_err * st.t.ppf((1 + confidence) / 2, n - 1)  # t-critical value\n",
        "\n",
        "    return mean - margin_of_error, mean + margin_of_error\n",
        "\n",
        "# Example usage:\n",
        "sample_data = [12, 15, 14, 10, 13, 17, 16, 14, 15, 11]\n",
        "ci = confidence_interval(sample_data, 0.95)\n",
        "print(f\"95% Confidence Interval: {ci}\")\n"
      ],
      "metadata": {
        "id": "8Jhy91-J_GMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "def margin_of_error(sample_std_dev, sample_size, confidence_level):\n",
        "\n",
        "    alpha = 1 - confidence_level\n",
        "    z_score = stats.norm.ppf(1 - alpha / 2)  # Z-score for two-tailed test\n",
        "    standard_error = sample_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "    return z_score * standard_error\n",
        "\n",
        "# Example\n",
        "if __name__ == \"__main__\":\n",
        "    sample_std_dev = float(input(\"Enter sample standard deviation: \"))\n",
        "    sample_size = int(input(\"Enter sample size: \"))\n",
        "    confidence_level = float(input(\"Enter confidence level (e.g., 0.95 for 95%): \"))\n",
        "\n",
        "    moe = margin_of_error(sample_std_dev, sample_size, confidence_level)\n",
        "    print(f\"Margin of Error: {moe}\")"
      ],
      "metadata": {
        "id": "kgdzjjag_iDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "def bayes_theorem(prior, likelihood, false_positive):\n",
        "    # Compute marginal probability P(E)\n",
        "    marginal = (likelihood * prior) + (false_positive * (1 - prior))\n",
        "\n",
        "    # Compute posterior probability P(H|E)\n",
        "    posterior = (likelihood * prior) / marginal\n",
        "    return posterior\n",
        "\n",
        "# Given probabilities\n",
        "P_H = 0.01  # Prior probability of having the disease\n",
        "P_E_H = 0.9  # Likelihood (test positive given disease)\n",
        "P_E_notH = 0.05  # False positive rate\n",
        "\n",
        "# Compute posterior probability\n",
        "P_H_E = bayes_theorem(P_H, P_E_H, P_E_notH)\n",
        "print(f\"Posterior Probability (P(H|E)): {P_H_E}\")\n"
      ],
      "metadata": {
        "id": "cIbR6Hy4AAMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Perform a Chi-square test for independence between two categorical variables in Python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Contingency table: Rows = Gender, Columns = Product Preference\n",
        "# Example data\n",
        "data = np.array([[30, 10],   # Males: 30 prefer A, 10 prefer B\n",
        "                 [20, 40]])  # Females: 20 prefer A, 40 prefer B\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(data)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:}\")\n",
        "print(f\"P-value: {p_value:}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant association between Gender and Preference.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant association between Gender and Preference.\")\n"
      ],
      "metadata": {
        "id": "6MvS_CtSAoAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "import numpy as np\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    observed = np.array(observed)\n",
        "    row_totals = observed.sum(axis=1).reshape(-1, 1)\n",
        "    col_totals = observed.sum(axis=0).reshape(1, -1)\n",
        "    grand_total = observed.sum()\n",
        "\n",
        "    expected = (row_totals @ col_totals) / grand_total\n",
        "    return expected\n",
        "\n",
        "# Example observed frequency table\n",
        "observed_data = [\n",
        "    [50, 30, 20],\n",
        "    [30, 50, 20],\n",
        "    [20, 30, 50]]\n",
        "\n",
        "\n",
        "expected_frequencies = calculate_expected_frequencies(observed_data)\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected_frequencies)\n",
        "\n"
      ],
      "metadata": {
        "id": "7X9A4fG2CCKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed frequencies from rolling a die 60 times\n",
        "observed = np.array([8, 12, 10, 15, 9, 6])  # Counts for faces 1-6\n",
        "\n",
        "# Expected frequencies if the die were fair (60 rolls, 6 faces)\n",
        "expected = np.full(6, 60 / 6)  # Each face should appear 10 times\n",
        "\n",
        "# Perform Chi-Square Goodness-of-Fit Test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Output results\n",
        "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The die is NOT fair.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant evidence that the die is unfair.\")\n"
      ],
      "metadata": {
        "id": "Pnaq3IlzCdyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15.  Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def simulate_chi_square(df, num_samples=10000):\n",
        "    \"\"\"Simulates Chi-square distribution with given degrees of freedom.\"\"\"\n",
        "    chi_square_samples = np.random.chisquare(df, num_samples)\n",
        "    return chi_square_samples\n",
        "\n",
        "def plot_chi_square_distribution(df_values, num_samples=10000):\n",
        "    \"\"\"Plots the Chi-square distribution for different degrees of freedom.\"\"\"\n",
        "    x = np.linspace(0, max(df_values) * 4, 1000)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for df in df_values:\n",
        "        samples = simulate_chi_square(df, num_samples)\n",
        "        plt.hist(samples, bins=50, density=True, alpha=0.5, label=f'df={df}')\n",
        "        plt.plot(x, stats.chi2.pdf(x, df), lw=2)\n",
        "\n",
        "    plt.title('Chi-square Distribution')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Define degrees of freedom to visualize\n",
        "df_values = [1, 2, 5, 10]\n",
        "plot_chi_square_distribution(df_values)"
      ],
      "metadata": {
        "id": "IlFCp44TC212"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16.Implement an F-test using Python to compare the variances of two random samples\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "# Generate two random samples\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10, n=30\n",
        "sample2 = np.random.normal(loc=50, scale=15, size=30)  # Mean=50, Std=15, n=30\n",
        "\n",
        "# Compute sample variances\n",
        "var1 = np.var(sample1, ddof=1)  # Sample variance (unbiased)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Compute the F-statistic\n",
        "F = var1 / var2 if var1 > var2 else var2 / var1  # Ensure F >= 1\n",
        "df1 = len(sample1) - 1  # Degrees of freedom for the numerator\n",
        "df2 = len(sample2) - 1  # Degrees of freedom for the denominator\n",
        "\n",
        "# Compute p-value (two-tailed test)\n",
        "p_value = 2 * (1 - f.cdf(F, df1, df2))  # Two-tailed test\n",
        "\n",
        "# Output results\n",
        "print(f\"Variance of Sample 1: {var1}\")\n",
        "print(f\"Variance of Sample 2: {var2}\")\n",
        "print(f\"F-statistic: {F:.4f}\")\n",
        "print(f\"Degrees of freedom: ({df1}, {df2})\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variances.\")\n"
      ],
      "metadata": {
        "id": "ZzwNIaSkDJOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def perform_anova(*groups):\n",
        "\n",
        "    # Perform ANOVA\n",
        "    f_stat, p_value = stats.f_oneway(*groups)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"F-statistic: {f_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Interpret the result\n",
        "    alpha = 0.05  # Significance level\n",
        "    if p_value < alpha:\n",
        "        print(\"Conclusion: There is a significant difference between the group means (reject H0).\")\n",
        "    else:\n",
        "        print(\"Conclusion: There is no significant difference between the group means (fail to reject H0).\")\n",
        "\n",
        "# Example data for three groups\n",
        "group1 = np.array([23, 27, 24, 20, 28, 22, 26])\n",
        "group2 = np.array([30, 35, 32, 31, 29, 34, 36])\n",
        "group3 = np.array([41, 45, 43, 44, 40, 42, 46])\n",
        "\n",
        "# Perform ANOVA\n",
        "do_anova_test = perform_anova(group1, group2, group3)"
      ],
      "metadata": {
        "id": "om8KSmOJDhu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18.Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sample Data: Three groups with different means\n",
        "np.random.seed(42)  # For reproducibility\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)  # Mean 50\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)  # Mean 55\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)  # Mean 60\n",
        "\n",
        "# Perform One-Way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print ANOVA Results\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the group means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the group means.\")\n",
        "\n",
        "# Visualization\n",
        "data = {\"Values\": np.concatenate([group1, group2, group3]),\n",
        "    \"Group\": ([\"Group 1\"] * len(group1)) + ([\"Group 2\"] * len(group2)) + ([\"Group 3\"] * len(group3))}\n",
        "\n",
        "# Create a boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x=data[\"Group\"], y=data[\"Values\"], palette=\"Set2\")\n",
        "plt.title(\"One-Way ANOVA: Group Comparisons\")\n",
        "plt.xlabel(\"Groups\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mqk6f47uD4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19.Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def check_anova_assumptions(*groups, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Checks assumptions for ANOVA: normality and equal variance.\n",
        "\n",
        "    Parameters:\n",
        "        groups: Variable number of arrays/lists containing data for each group.\n",
        "        alpha: Significance level (default is 0.05).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with normality and equal variance test results.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Normality test for each group\n",
        "    normality_pvalues = [stats.shapiro(group)[1] for group in groups]\n",
        "    normality_check = all(p > alpha for p in normality_pvalues)\n",
        "    results[\"normality\"] = {\"passed\": normality_check,\"p-values\": normality_pvalues}\n",
        "\n",
        "    # Equal variance (homogeneity) test\n",
        "    levene_stat, levene_p = stats.levene(*groups)\n",
        "    results[\"equal_variance\"] = {\"passed\": levene_p > alpha,\"p-value\": levene_p}\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "group1 = np.random.normal(10, 2, 30)\n",
        "group2 = np.random.normal(12, 2, 30)\n",
        "group3 = np.random.normal(11, 2, 30)\n",
        "\n",
        "assumptions = check_anova_assumptions(group1, group2, group3)\n",
        "print(assumptions)\n"
      ],
      "metadata": {
        "id": "gNUVv1JfERk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Generate a sample dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create categorical factors\n",
        "factor_A = np.repeat(['Low', 'High'], 30)\n",
        "factor_B = np.tile(['Type1', 'Type2', 'Type3'], 20)\n",
        "\n",
        "# Generate a continuous dependent variable with some interaction effect\n",
        "data = np.random.normal(50, 10, 60) + (np.array([0 if a == 'Low' else 5 for a in factor_A])\n",
        "                                       + np.array([0 if b == 'Type1' else 3 for b in factor_B]))\n",
        "\n",
        "df = pd.DataFrame({'Factor_A': factor_A, 'Factor_B': factor_B, 'Score': data})\n",
        "\n",
        "# Perform two-way ANOVA\n",
        "model = ols('Score ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Print ANOVA table\n",
        "print(anova_table)\n",
        "\n",
        "# Visualize interaction effects\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.pointplot(x=\"Factor_B\", y=\"Score\", hue=\"Factor_A\", data=df, dodge=True, markers=[\"o\", \"s\"], capsize=0.1)\n",
        "plt.title(\"Interaction Plot: Factor_A vs Factor_B on Score\")\n",
        "plt.ylabel(\"Mean Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pdTYck86Etu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def plot_f_distribution(df1, df2, x_max=5, num_points=1000):\n",
        "    x = np.linspace(0, x_max, num_points)\n",
        "    y = stats.f.pdf(x, df1, df2)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})')\n",
        "    plt.fill_between(x, y, alpha=0.3)\n",
        "    plt.axvline(stats.f.ppf(0.95, df1, df2), color='r', linestyle='dashed', label='Critical value (α=0.05)')\n",
        "    plt.xlabel('F Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title('F-Distribution')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "df1, df2 = 5, 10  # Example degrees of freedom\n",
        "plot_f_distribution(df1, df2)"
      ],
      "metadata": {
        "id": "LZGYSGJzFDHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22.  Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate synthetic data for three groups\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=30)\n",
        "group2 = np.random.normal(loc=55, scale=10, size=30)\n",
        "group3 = np.random.normal(loc=60, scale=10, size=30)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Display results\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Visualize using a boxplot\n",
        "data = [group1, group2, group3]\n",
        "labels = ['Group 1', 'Group 2', 'Group 3']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=data)\n",
        "plt.xticks(ticks=[0, 1, 2], labels=labels)\n",
        "plt.xlabel(\"Groups\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.title(\"Boxplot of Different Groups\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ghkJlwpZFQH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means"
      ],
      "metadata": {
        "id": "MTEcdVNjFlKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results"
      ],
      "metadata": {
        "id": "-ZQI0KzsF_Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test_proportions(successes1, n1, successes2, n2):\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters:\n",
        "    successes1 (int): Number of successes in group 1\n",
        "    n1 (int): Total sample size in group 1\n",
        "    successes2 (int): Number of successes in group 2\n",
        "    n2 (int): Total sample size in group 2\n",
        "\n",
        "    Returns:\n",
        "    z_score (float): The computed Z-score\n",
        "    p_value (float): The p-value for the test\n",
        "    \"\"\"\n",
        "    # Compute sample proportions\n",
        "    p1 = successes1 / n1\n",
        "    p2 = successes2 / n2\n",
        "\n",
        "    # Compute pooled proportion\n",
        "    p_pool = (successes1 + successes2) / (n1 + n2)\n",
        "\n",
        "    # Compute standard error\n",
        "    se = np.sqrt(p_pool * (1 - p_pool) * (1/n1 + 1/n2))\n",
        "\n",
        "    # Compute Z-score\n",
        "    z_score = (p1 - p2) / se\n",
        "\n",
        "    # Compute p-value (two-tailed test)\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    return z_score, p_value\n",
        "\n",
        "# Example\n",
        "successes_group1 = 50\n",
        "sample_size_group1 = 200\n",
        "successes_group2 = 30\n",
        "sample_size_group2 = 180\n",
        "\n",
        "z, p = z_test_proportions(successes_group1, sample_size_group1, successes_group2, sample_size_group2)\n",
        "print(f\"Z-score: {z}\")\n",
        "print(f\"P-value: {p}\")"
      ],
      "metadata": {
        "id": "o5edv7LVGtof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26 Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate two random datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10, Size=30\n",
        "data2 = np.random.normal(loc=50, scale=15, size=30)  # Mean=50, Std=15, Size=30\n",
        "\n",
        "# Compute sample variances\n",
        "var1 = np.var(data1, ddof=1)  # Sample variance (unbiased)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "\n",
        "# Compute the F-statistic (larger variance in numerator)\n",
        "if var1 > var2:\n",
        "    F = var1 / var2\n",
        "    df1, df2 = len(data1) - 1, len(data2) - 1\n",
        "else:\n",
        "    F = var2 / var1\n",
        "    df1, df2 = len(data2) - 1, len(data1) - 1\n",
        "\n",
        "# Compute the p-value (two-tailed test)\n",
        "p_value = 2 * min(stats.f.cdf(F, df1, df2), 1 - stats.f.cdf(F, df1, df2))\n",
        "\n",
        "# Compute critical values for a 95% confidence level\n",
        "alpha = 0.05\n",
        "F_critical_low = stats.f.ppf(alpha / 2, df1, df2)\n",
        "F_critical_high = stats.f.ppf(1 - alpha / 2, df1, df2)\n",
        "\n",
        "# Visualization\n",
        "x = np.linspace(0.1, 5, 500)\n",
        "y = stats.f.pdf(x, df1, df2)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label=f'F-distribution (df1={df1}, df2={df2})', color='blue')\n",
        "plt.axvline(F, color='red', linestyle='--', label=f'Observed F={F:.2f}')\n",
        "plt.axvline(F_critical_low, color='green', linestyle='--', label=f'Critical F low={F_critical_low:.2f}')\n",
        "plt.axvline(F_critical_high, color='green', linestyle='--', label=f'Critical F high={F_critical_high:.2f}')\n",
        "plt.fill_between(x, y, where=(x <= F_critical_low) | (x >= F_critical_high), color='gray', alpha=0.3, label=\"Rejection Region\")\n",
        "plt.xlabel(\"F-value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"F-test for Equality of Variances\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Interpretation\n",
        "F, p_value, F_critical_low, F_critical_high\n"
      ],
      "metadata": {
        "id": "-AuC0_cQHfUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulating observed data\n",
        "np.random.seed(42)\n",
        "observed = np.random.randint(20, 100, size=5)  # Random counts for 5 categories\n",
        "\n",
        "# Defining expected proportions (assuming equal probability for each category)\n",
        "expected_proportions = np.full_like(observed, fill_value=np.mean(observed))\n",
        "\n",
        "# Performing the Chi-square test for goodness of fit\n",
        "chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected_proportions)\n",
        "\n",
        "# Displaying results\n",
        "chi2_stat, p_value\n"
      ],
      "metadata": {
        "id": "QO-L_PIQH35J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}